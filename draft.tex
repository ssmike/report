\documentclass[pdftex,ptm,14pt,a4paper]{extreport}

\usepackage[utf8]{inputenc}

\usepackage[russian,english]{babel}
    \addto{\captionsenglish}{\renewcommand{\bibname}{Литература}}
    \addto\captionsenglish{\renewcommand{\figurename}{Рис.}}
    \addto\captionsenglish{\renewcommand{\contentsname}{Содержание}}
    \addto\captionsenglish{\renewcommand{\proofname}{Доказательство}}
\usepackage[T2A]{fontenc}

\makeatletter
\renewcommand*{\ps@plain}{%
  \let\@mkboth\@gobbletwo
  \let\@oddhead\@empty
  \def\@oddfoot{%
    \reset@font
    \hfil
    \thepage
    % \hfil % removed for aligning to the right
  }%
  \let\@evenhead\@empty
  \let\@evenfoot\@oddfoot
}

\usepackage{csquotes}

\usepackage[backend=bibtex]{biblatex}
\bibliography{draft}

\makeatother
\pagestyle{plain}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{cmap}
\usepackage{verbatim}
\usepackage[table,xcdraw]{xcolor}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{graphicx}

%\usepackage{bbm, dsfont}


\makeatletter
\renewcommand{\@chapapp}{Часть}
\makeatother

% Theorem Styles
\newtheorem{theorem}{Теорема}[chapter]
\newtheorem{lemma}[theorem]{Лемма}
\newtheorem{claim}[theorem]{Теорема}
% Definition Styles
\theoremstyle{definition}
\newtheorem{definition}{Определение}[chapter]
\newtheorem{example}{Пример}[chapter]

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

%\usepackage{minted}
%\graphicspath{ {my path} }
%\includegraphics[scale=0.5]{name.png}

%\inputminted{syntax}{code}

% \begin-end{lstlisting}
\catcode`@=11
\def\caseswithdelim#1#2{\left#1\,\vcenter{\normalbaselines\m@th
  \ialign{\strut$##\hfil$&\quad##\hfil\crcr#2\crcr}}\right.}% you might like it without the \strut
\catcode`@=12
%
\def\bcases#1{\caseswithdelim[{#1}}
\def\vcases#1{\caseswithdelim|{#1}}
%

\title{}
\author{М.С. Сурин}
\DeclareMathOperator{\sgn}{sgn}

\begin{document}
\begin{comment}
    \begin{titlepage}
    \newpage

    \begin{center}
    МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ ФЕДЕРАЦИИ \\
    \vspace{0.5cm}
    ГОСУДАРСТВЕННОЕ ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ \\*
    ВЫСШЕГО ПРОФЕССИОНАЛЬНОГО ОБРАЗОВАНИЯ\\*
    "МОСКОВСКИЙ ФИЗИКО-ТЕХНИЧЕСКИЙ ИНСТИТУТ \\*
    (ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ)" \\*
    \vspace{0.5cm}
    ФАКУЛЬТЕТ ИННОВАЦИЙ И ВЫСОКИХ ТЕХНОЛОГИЙ \\*
    КАФЕДРА АНАЛИЗА ДАННЫХ \\*
    \hrulefill
    \end{center}


    \vspace{8em}

    \begin{center}
    \Large Выпускная квалификационная работа по направлению 01.03.02 <<Прикладные математика и информатика>> \linebreak НА ТЕМУ:
    \end{center}

    \vspace{2.5em}

    \begin{center}
    \textsc{\large{\textbf{TITLE}}}
    \end{center}

    \vspace{6.5em}

    \begin{flushleft}
        Студент \hrulefill Сурин М.С.  \\
    \vspace{1.5em}
        Научный руководитель к.ф-м.н \hrulefill Артемов А.В.\\
    \vspace{1.5em}
    Зам. зав. кафедрой д.ф-м.н, профессор \hrulefill Бунина Е.И.
    \end{flushleft}

    \vspace{\fill}

    \begin{center}
    МОСКВА, 2017
    \end{center}

    \end{titlepage}
\end{comment}

\tableofcontents

\sloppy

\chapter{Введение}
Тестирование распределённых и устойчивых к сбоям баз данных является более сложной задачей чем тестирование монолитных систем
в силу асинхронности сети(\cite{network-reliable}) и возможности аппаратных сбоев.
В частности, при тестировании распределённых баз данных возникает потребность в верификации гарантий, которые даёт тестируемая система.
В данной работе используется метод внесения неисправностей(fault injection) для верификации подсистем Yandex.YT.

\chapter{Обзор литературы}
В данной главе сделан обзор существующих методов
верификации гарантий консистентности распределённых систем.

\section{Формальные спецификации}
Метод формальных спецификаций заключается в построении математической модели системы, формализации требований к ней и последующему
доказательству того, что система удовлетворяет поставленным требованиям. Обычной практикой является использование инструментов, позволяющих получить доказательство в полуавтоматическом режиме(\cite{coq}).
Построение формальных спецификаций полезно при доказательстве корректности модели соответствующей
системы, но  в случае, если модель оказывается достаточно громоздкой, возникают вопросы
соответствия этой модели реальной системе, а также проблемы обновления модели при изменении её функциональности.
Данные ограничения, как отмечают авторы в \cite{models-bounds} сильно повышают стоимость поддержки
и делают данный подход оправданным только для критичных систем.
Впрочем, достаточно большие компании, такие как Amazon, всё-таки могут позволить себе использование формальных моделей
(\cite{amazon-formal-proofs}) наряду с другими методами.

\section{Внесение неисправностей}
Метод внесения неисправностей заключается в искусственном создании неисправностей(аппаратных сбоев), направленном на
тестирование отказоустойчивости системы. Применительно к распределённым системам это такие неисправности, как искусственные разрывы сети или
отказы вычислительных узлов. В отличие от построения спецификаций данный метод не позволяет доказать корректность, но является гораздо менее накладным, а так же не оперирует с производными от конечного продукта(формальной моделью), что расширяет область применения.
Netflix использует этот подход(\cite{netflix-simian-army}) для тестирования своих сервисов.
Многие системы с открытым исходным кодом тестировались при помощи фреймворка jepsen(\cite{jepsen-io}, \cite{jepsen-analyses}), который
упрощает внесение неисправностей(искусственные разрывы сети, и т.д.).
Также существуют примеры применения
гибридных методики, такие как lineage-driven fault injection(\cite{molly}) -- когда вместо того, чтобы тестировать
систему методом чёрного ящика, используется знание протокола, и избирательно теряются сообщения между узлами.
\chapter{Постановка задачи}
В данной работе мы верифицируем подсистемы Yandex.YT, а именно “Кипарис” и “Динамические таблицы”.
Существуют следующие типы нарушений консистентности, которые необходимо обнаружить.
\begin{itemize}
    \item Потеря подтверждённых записей.
    \item Чтение устаревшего состояния.
    \item Чтение данных, появившихся в результате неподтверждённых записей.
\end{itemize}

\section{Кипарис}
“Кипарис” -- распределённое хранилище \guillemotleftключ-значение\guillemotright.
Является CP системой в смысле CAP-теоремы и гарантирует линеаризуемость \cite{linearizable}.

Схема репликации “Кипариса” схожа с идеями, применёнными в Zookeeper \cite{zookeeper} и Raft \cite{raft}.

“Кипарис” запущен на кластере из $2n+1$ машин.
У каждого узла “Кипариса” есть 3 режима работы: лидер, последователь и режим восстановления.

Лидер определяется в процессе голосования, которое устроено следующим образом:
\begin{enumerate}
    \item Узлы рассылают всему кластеру длину записанной истории и свой идентификатор,
    \item Узлы выбирают лидера (узел с наименьшим идентификатором среди имеющих наибольшую длину истории)
        и рассылают остальным идентификатор выбранного лидера.
    \item Узел, за которого проголосовали не менее $n+1$ узлов становится лидером.
\end{enumerate}
Далее каждый узел хранит идентификатор лидера.
Периодически лидер опрашивает последователей, и если не набирается $n$ узлов, для которых верно,
что идентификатор их лидера совпадает с опрашивающим узлом, то начинаются выборы.
Также выборы начинаются, если в течение заранее заданного промежутка времени какой-либо из последователей не был опрошен лидером.

При записи (любом мутирующем запросе) клиент обращается к лидеру, который в свою очередь опрашивает последователей и
реплицирует на них запрос. Лидер отвечает успехом если по крайней мере $n$ последователей подтвердили что их хранимый идентификатор
лидера совпадает с опрашивающим узлом, и они записали изменение на диск.

На запросы чтения лидер отвечает без подтверждения от последователей.
Последователи отвечают на запрос чтения только после того как получено подтверждение от лидера о том, состояние узла не отстаёт от лидера.
Узлы в режиме восстановления на запросы чтения не отвечают. Более того, узлы в режиме восстановления не голосуют при выборах, а только
асинхронно забирают изменения с лидера.

\section{Динамические таблицы}
“Динамические таблицы” -- это также CP-хранилище
\guillemotleftключ-значение\guillemotright,
в свою очередь являющееся Snapshot-сериализуемым\cite{snapshot-serializable}.
Пространство ключей статически шардировано. Для координации используется “Кипарис”.
А именно, в нем хранится информация о шардах. Также “Кипарис” служит timestamp-поставщиком.

Каждый шард устроен следующим образом: некоторый узел объявляется главным,
статически назначаются вторичные узлы на которые будут реплицироваться изменения главного
Далее при каждой операции на главном узле собирается кворум вторичных узлов.

В данной работе мы тестируем транзакции, которые устроены следующим образом:
В начале транзакции клиент получает timestamp и все чтения в рамках транзакции
производит по нему же. Чтение возвращает наиболее свежую версию данных до полученного
timestamp. При завершении транзакции возможно два принципиально разных случая:
\begin{itemize}
    \item В случае если записи затрагивают 1 шард, этот же шард просто выполняет записи.
    \item В случае если записи затрагивают несколько шардов, используется алгоритм
        двухфазного коммита \cite{tanenbaum2007distributed}.
        А именно,
        \subitem Клиент отправляет запрос всем затронутым шардам.
        \subitem После получения положительного ответа от всех участников,
            случайный шард назначается координатором и на него же клиент отправляет
            запрос на коммит.
        \subitem Координатор отправляет запрос на подготовку коммита всем участникам.
        \subitem После подтверждения всеми участниками, генерируется timestamp и
            отправляется подтверждение всем участникам.
        \subitem После получения подтверждения от всех участников, отправляется ответ клиенту.
\end{itemize}

\chapter{Предложенный алгоритм}
В данной работе мы пользуемся фреймворком jepsen(\cite{jepsen-io}).
Общая схема процедуры верификации такова:
В несколько потоков делаются серии запросов к базе, развёрнутой на кластере размера 3-5.
Запросы и ответы собираются в единую последовательную историю событий, которая в дальнейшем
 проверяется на соответствие заявленным гарантиям.
\section{jepsen}
Jepsen представляет собой библиотеку для написания тестов и состоит из следующих частей:
\begin{itemize}
    \item \textbf{core} -- основной модуль, управляющий установкой и настройкой тестируемой базы,
        запуском потоков, инициирующих запросы к базе. Запросы, а также моделируемые неисправности
        генерируются при помощи данного на вход  генератора и инициируются данным модулем.
        Также передаёт полученную историю модулю \textbf{checker}, и генерирует отчёт.
    \item \textbf{gen} -- модуль, предназначенный для генерации запросов, неисправностей и т.п..
        Представляет из себя набор элементарных генераторов и операторы для их комбинирования.
    \item \textbf{nemesis} -- модуль для внедрения неисправностей, предназначен для запуска
        отдельного рабочего потока, который создаёт искусственные разрывы сети между узлами,
        имитирует сбои отдельных узлов, манипулирует со временем на узлах и т.п..
    \item \textbf{model} -- Предоставляет модель состояния базы, предназначен для проверки правильности результатов запросов.
    \item \textbf{checker} -- Модуль для интеграции пользовательских анализаторов истории с jepsen.
\end{itemize}
\section{Верификация истории}
\subsection{Кипарис}
\label{cypress-verify}
Для верификации линеаризуемости используется классический алгоритм J. Wing, C.Gong \cite{wing-testing}
с дополнениями G. Lowe \cite{lowe-testing} и A. Horn \cite{horn-faster}.
Приведём краткую схему работы алгоритма.
\begin{definition}[Модель]
    Для множества $\Xi$, некоторого множества $\Delta,$ множества операций $\chi \subset (\Xi \times \Delta)^\Xi.$
    Будем называть $\langle \Xi, \Delta, \chi \rangle$ моделью.
\end{definition}

\begin{definition}[История]
    Для модели $\langle \Xi, \Delta, \chi \rangle$ будем называть историей последовательность событий вида
    \begin{itemize}
        \item \textit{call.process.op}, где process --  идентификатор процесса,
             $\textit{op}: \Xi \rightarrow \langle \Xi, \Delta \rangle$  -- производимая операция над состоянием разделяемого объекта.
        \item \textit{ret.process.response} process -- идентификатор процесса,
            $\textit{response} = \langle \textit{status}, \textit{value} \rangle,
            \textit{value} \in \Delta,
            \textit{status} \in \{\textbf{fail},\textbf{ok},\textbf{info}\}$
            Здесь и далее
        \subitem \textit{fail} -- детерминировано отвергнутая операция,
        \subitem \textit{ok} -- успешная операция.
        \subitem \textit{info} -- неизвестно, отвергнута операция или нет(моделирует превышение таймаута и проч.).
    \end{itemize}
\end{definition}

\begin{definition}[Полная история]
    История является полной, если история, ограниченная на любой процесс, удовлетворяет следующим требованиям:
    \begin{itemize}
        \item История начинается с \textit{call}-записи.
        \item За каждой \textit{call}-записью которая не является последней в истории
            следует соответствующая \textit{ret}-запись,
            за \textit{ret} записью может следовать только другая \textit{call}-запись.
        \item Для всех \textit{ret}-записей $\textit{status} = \textbf{ok}.$
    \end{itemize}
\end{definition}

Алгоритм оперирует с полной историей, которая может быть получена из реальной удалением
детерминировано неудачных операций и $\textbf{info}$-записей и представляет из себя обход некоторого графа состояний.

Также отметим что при проведении экспериментов в случае если операция завершилась с \textbf{info}
то идентификатор процесса данной операции далее использоваться не может и соответствующий
логический процесс необходимо считать завершённым.

\begin{definition}[Состояние]
    Будем называть состоянием $\langle \textit{state}, \textit{history} \rangle$ где
    $\textit{state} \in \Xi,$ $\textit{history}$ -- полная история.
\end{definition}

Для $\langle \textit{state}, \textit{history} \rangle$ будем считать смежными
состояния вида $op\lbrack state\rbrack, history \backslash op$ где
\textit{op} -- $call$ запись принадлежащая \textit{history} которой не предшествует ни одна
$ret$ запись, $history \backslash op$ -- история с удалённой $op$ и соответствующей $ret$-записью
(если таковая есть).

История считается линеаризуемой при достижимости состояния с $history$ без $ret$-записей из начального
состояния, в котором $history$ -- полная исследуемая история. Корректность данного утверждения
доказана в \cite{wing-testing}.

При постановке экспериментов использовалась реализация из библиотеки knossos(\cite{knossos}),
запоминающая исследованные состояния в хеш-таблице. Также, перед началом работы алгоритма явно строится
граф состояний и переходов для модели, что сильно уменьшает время работы.

\subsection{Динамические таблицы}
\label{dt-verify}
Для верификации snapshot-сериализуемости использовалась модификация вышеупомянутого алгоритма
J. Wing, C.Gong, G. Lowe.

Данный алгоритм работает с конкретной моделью базы $\Xi.$
А именно, для некоторого количества регистров $n$ и множества значений $S$
$\Xi = S^n$

Поддерживаемые операции:
\begin{itemize}
    \item{$start(S)$} Начать транзакцию, прочитать значения регистров из S.
    \item{$commit(S, V)$} Завершить транзакцию, записать в регистры из $S$ значения $V$.
\end{itemize}

Верифицируемые истории при ограничении на любой процесс должны являться чередующимися последовательностями
$start$ и $commit$ операций. Более того, мы требуем чтобы ограниченные истории начинались с $start$ операции.

Сформулируем определение snapshot-сериализуемости для описанной модели.

\begin{definition}
    \label{snapshot-def}
    Будем называть историю H snapshot-сериализуемой если существует линеаризация \cite{linearizable}.
    В которой для любой пары $(u, v)$ соответствующих $start$ и $commit$ операций, между u и v нет ни одной
    $commit$ операции которая записывает в регистры, записываемые $v$.
\end{definition}

Первым шагом алгоритм преобразует исходную историю в некоторое множество историй для другой модели
$\Xi = (S\times\{0, 1\})^n.$

Неформально, транзакции будут блокировать регистры в которые планируют писать и соответственно
состояние разделяемого объекта теперь включает в себя информацию о заблокированных ячейках.
Далее будем говорить о регистрах, которые могут быть заблокированы.

Для каждой пары соответствующих $start$ и $commit$ операций
\begin{itemize}
    \item Если $commit$ операция завершилась \textbf{fail}-записью, обе записи
        соответствующие $commit$ операции удаляются.
        $start$ операция преобразуется в $read$ операцию для того-же множества регистров.
        То есть не меняющее состояние объекта чтение.
    \item Если $commit$ операция завершилась \textbf{ok}-записью, то
        $start$-операция преобразуется в $read$ операцию, блокирующую регистры,
        в которые пишет $commit$ операция. Соответственно операция определена только на объектах,
        в которых соответствующие регистры не заблокированы. $commit$ операция преобразуется в
        $write$ операцию, при этом разблокирующую регистры в которые пишет.
        Соответственно определена только на объектах, в которых соответствующие регистры заблокированы.
    \item Если $commit$ операция не завершилась или завершилась \textbf{info}-записью, то рассматриваем два варианта истории,
        преобразованной одним из вышеупомянутых способов.
\end{itemize}

Таким образом получаем некоторое множество историй.
\begin{lemma}
    Snapshot-сериализуемость исходной истории равносильна линеаризуемости одной из историй, полученных
    приведённым преобразованием.
\end{lemma}
\begin{proof}
    В одну из сторон приведённое утверждение очевидно. То есть из snapshot-сериализуемости очевидна линеаризуемость
    одной из полученных историй. Пусть $T$ получена из $H$ и $L$ -- линеаризация $T.$ Покажем как построить линеаризацию
    $H$ удовлетворяющую \ref{snapshot-def}. Рассмотрим $L'$ соответствующую $L.$ В том смысле, что операции в $L'$ получаются
    из операций в $L$ игнорированием блокировки регистров. $read$-записям соответствуют $start$-записи,
    $write$ переходят в $commit$. Рассмотрим ограничение $L$ на один из регистров. Также удалим неблокирующие чтения.
    Из определения операций очевидно, что чтения и записи чередуются, и история начинается с чтения.
    Покажем, что история устроена следующим образом: каждой записи предшествует соответствующее чтение(с тем же идентификатором
    процесса), устанавливающее блокировку и за каждым чтением следует соответствующая запись. От противного: пусть пара $u$, $v$
    -- последовательные чтение и запись с разными идентификаторами процесса. Тогда в истории должно присутствовать соответствующее
    $v$ чтение $w$. Более того, оно должно быть расположено перед $u.$ Тогда после него должна быть запись с другим идентификатором
    процесса. Получаем противоречие с тем что пара $u, v$ первая. Пусть теперь пара $u$, $v$ в $L'$ -- соответствующие $start$ и
    $commit$ операции. Пусть между $u$ и $v$ есть $w$ которая пишет в один из регистров, в которые пишет $v.$ Тогда ограничивая $L$ на
    этот регистр получаем противоречие вышедоказанному.
\end{proof}

Алгоритм устроен следующим образом:
\begin{itemize}
    \item Сначала строится преобразование истории: при неоднозначности преобразования элементом истории является кортеж альтернатив.
        у $ret$-записей альтернатив нет. Для некоторых записей помечаем что при выполнении следующую операцию
        данного процесса надо игнорировать.
    \item Удаляются все \textbf{fail} и \textbf{info} записи. Для \textbf{fail}-записей необходимо удалить также \textbf{call}-записью.
    \item Производится поиск в пространстве состояний, схожий с описанным в разделе \ref{cypress-verify}.
\end{itemize}

Состоянием так же является $\langle state, history \rangle.$
При вычислении смежных состояний мы рассматриваем все альтернативы для каждой \textbf{call}-записи, и удаляем
из истории следующую операцию процесса(если помечено что надо её проигнорировать).
При поиске запоминаем пройденные состояния, в том смысле что запоминаем пару (множество удалённых операций, состояние).
В \cite{horn-faster} запоминали именно пару $\langle state, history \rangle,$ что создавало некоторое замедление из-за
необходимости сравнения историй, которые хранились в неизменяемом односвязном списке. Авторы предлагают кешировать результаты
сравнения списков для ускорения работы алгоритма. Мы же, поддерживая множество удалённых операций(bitset) добились сравнимой
производительности при меньшей сложности алгоритма.

Как и в алгоритме, описанном в \ref{cypress-verify}, при постановке экспериментов,
перед началом работы алгоритма явно строится
граф состояний и переходов для модели, что сильно уменьшает время работы.

\chapter{Проведённые эксперименты}
\section{Кипарис}
Было исследовано поведение системы при следующих условиях.
\begin{itemize}
    \item Использовалась модель атомарного регистра, со следующими доступными типами операций:
        \begin{itemize}
            \item \textbf{read} -- Чтение значения регистра, возможны исходы:
                \begin{itemize}
                    \item \textbf{ok} -- Удалось прочитать значение регистра.
                    \item \textbf{fail} -- Не удалось прочитать значение.
                \end{itemize}
            \item \textbf{write} -- Запись в регистр, возможны исходы:
                \begin{itemize}
                    \item \textbf{ok} -- Удалось записать значение.
                    \item \textbf{fail} --  Хранилище отклонило операцию.
                    \item \textbf{unknown} -- Возможно удалось записать значение
                        (хранилище не отклонило и не подтвердило операцию).
                \end{itemize}
        \end{itemize}
        Соответственно, все операции с хранилищем производились по одному и тому же ключу.
    \item Запросы осуществлялись в 8 потоков, чтение с последователей разрешено.
    \item Для обнаружения ошибок в сетевую конфигурацию вносились сбои следующего вида:
    \subitem Кластер разбивался на две примерно равные части, также было исследовано поведение при разбиении
            на две равные части с одним узлом “перемычкой”, который видит остальные.
    \subitem Также было исследовано поведение алгоритма при периодических обрывах сети между текущим лидером
            и остальными узлами.
\end{itemize}
В исходной постановке считалось что исход любой неудавшейся записи -- \textbf{fail}.
После ряда экспериментов, были обнаружены аномалии вида "чтение неподтверждённых записей".
После анализа исходного кода, было обнаружено, что запросы записи нельзя однозначно считать отклонёнными системой.
В скорректированной постановке, ошибок линеаризации на данный момент обнаружено не было.

\section{Динамические таблицы}
Использовался алгоритм, описанный в \ref{dt-verify}.
Так как начало транзакции в исследуемой системе скорее логическое(клиент получает timestamp, и в дальнейшем
все чтения осуществляет по нему, то $start$ операции, завершившиеся по таймауту можно считать завершившимися
с \textbf{fail} статусом.
Было исследовано поведение системы при следующих условиях.
\begin{itemize}
    \item Размер кластера -- 5 узлов, 1 узел кипариса, 5 шардов.
    \item Запросы осуществлялись в 6 потоков. Было исследовано поведение системы при записях
        на 1 шард и на 2 шарда(распределённые коммиты).
    \item Для обнаружения ошибок в сетевую конфигурацию вносились сбои следующего вида:
        \subitem Кластер разбивался на две примерно равные части.
        \subitem Избирательно обрывалась сеть между узлами, обслуживающими случайный шард и мастером.
\end{itemize}

\printbibliography[title=Список литературы]
\end{document}
